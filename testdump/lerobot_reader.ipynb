{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2ed3c70",
   "metadata": {},
   "source": [
    "# LeRobot Dataset Reader (Quick Inspector)\n",
    "\n",
    "**Purpose:** Quickly load a LeRobot dataset (from the Hugging Face Hub or a local folder), peek at its structure, print shapes/dtypes, read meta info/stats, and visualize a few samples.\n",
    "\n",
    "- Works with LeRobot `v2.1` and `v3` APIs (tries both import paths).\n",
    "- Supports **Hub** or **local** loading (use the `root` argument for local folders).\n",
    "- Includes optional streaming and quick plots for actions and images.\n",
    "\n",
    "> References: LeRobot v3 loading examples and API tips are documented here: https://huggingface.co/docs/lerobot/en/lerobot-dataset-v3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4eafdc",
   "metadata": {},
   "source": [
    "## 0) Prerequisites\n",
    "\n",
    "Run this once in your environment/Colab. If you already have these packages, you can skip.\n",
    "\n",
    "```bash\n",
    "pip install -U lerobot datasets pandas matplotlib pillow pyarrow\n",
    "# Optional (only if you also need RLDS or TF-based utilities):\n",
    "# pip install -U tensorflow tensorflow_datasets\n",
    "# If you plan to train:\n",
    "# pip install -U torch torchvision torchaudio\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e1febf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Config — set how to find your dataset\n",
    "\n",
    "# # Option A — From the Hugging Face Hub (recommended)\n",
    "# USE_HUB = True\n",
    "REPO_ID = \"xX-Conan-Xx/pick_up_transparent_bottle\"  # e.g., \"your-username/your-dataset\"\n",
    "\n",
    "# Option B — Local dataset directory (the folder that contains `meta/`, `data/`, `videos/`)\n",
    "# If you recorded/converted locally or downloaded an archive, set LOCAL_ROOT to that folder.\n",
    "# If left empty, we'll fall back to the default cache (~/.cache/huggingface/lerobot/REPO_ID).\n",
    "LOCAL_ROOT = \"/media/zeyu/082b281d-ee9b-bc4b-be11-a1acf8642a75/Data/huggingface/lerobot/xX-Conan-Xx/pick_up_transparent_bottle/\"  # e.g., \"/path/to/my/le_rbt_dataset\"\n",
    "\n",
    "# Set to True to stream from Hub without downloading locally (v3 only)\n",
    "STREAM = False\n",
    "\n",
    "# How many frames to sample for the quick plots\n",
    "MAX_FRAMES = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6800a260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v2.x'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Imports and compatibility (v3 first, then v2 path as fallback)\n",
    "from pathlib import Path\n",
    "import os, json, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Do NOT set any specific matplotlib styles or colors here (keep defaults).\n",
    "\n",
    "# Try v3 import path first\n",
    "LeRobotDataset = None\n",
    "StreamingLeRobotDataset = None\n",
    "try:\n",
    "    from lerobot.datasets.lerobot_dataset import LeRobotDataset as _LRD\n",
    "    LeRobotDataset = _LRD\n",
    "    from lerobot.datasets.streaming_dataset import StreamingLeRobotDataset as _SLRD\n",
    "    StreamingLeRobotDataset = _SLRD\n",
    "    API_VERSION = \"v3\"\n",
    "except Exception:\n",
    "    # Fallback to older (v2.x) import path\n",
    "    try:\n",
    "        from lerobot.common.datasets.lerobot_dataset import LeRobotDataset as _LRD\n",
    "        LeRobotDataset = _LRD\n",
    "        API_VERSION = \"v2.x\"\n",
    "    except Exception as e:\n",
    "        raise ImportError(\n",
    "            \"Could not import LeRobotDataset from either v3 or v2 paths. \"\n",
    "            \"Please ensure `pip install -U lerobot` succeeded.\"\n",
    "        )\n",
    "\n",
    "API_VERSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cedb4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26eca5784bd4892a1fe26f43ee38ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6521034f03104559982c871ff7874140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/45 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d3feae04d724187bd0aac394bcabee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with API=v2.x\n",
      "Repo ID: xX-Conan-Xx/pick_up_transparent_bottle\n",
      "Number of indexable frames: 5680\n"
     ]
    }
   ],
   "source": [
    "# 3) Load the dataset (Hub/local/streaming)\n",
    "\n",
    "def _resolve_repo_id_from_local(local_root: str) -> str:\n",
    "    \"\"\"Try to read repo_id from meta/info.json if REPO_ID isn't set.\"\"\"\n",
    "    try:\n",
    "        info_p = Path(local_root) / \"meta\" / \"info.json\"\n",
    "        if info_p.exists():\n",
    "            with open(info_p, \"r\") as f:\n",
    "                info = json.load(f)\n",
    "            return info.get(\"repo_id\", \"\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    return \"\"\n",
    "\n",
    "if not REPO_ID and LOCAL_ROOT:\n",
    "    REPO_ID = _resolve_repo_id_from_local(LOCAL_ROOT)\n",
    "\n",
    "if STREAM:\n",
    "    if StreamingLeRobotDataset is None:\n",
    "        raise RuntimeError(\"StreamingLeRobotDataset is only available in LeRobot v3.\")\n",
    "    if not REPO_ID:\n",
    "        raise ValueError(\"For streaming, set REPO_ID (e.g., 'user/dataset').\")\n",
    "    dataset = StreamingLeRobotDataset(REPO_ID)\n",
    "else:\n",
    "    # Normal (non-streaming) mode; pass root if provided to prefer a local folder\n",
    "    kwargs = {}\n",
    "    if LOCAL_ROOT:\n",
    "        kwargs[\"root\"] = LOCAL_ROOT\n",
    "    if not REPO_ID:\n",
    "        raise ValueError(\"Please set REPO_ID (and optionally LOCAL_ROOT).\")\n",
    "    dataset = LeRobotDataset(REPO_ID, **kwargs)\n",
    "\n",
    "print(f\"Loaded dataset with API={API_VERSION}\")\n",
    "print(\"Repo ID:\", REPO_ID)\n",
    "try:\n",
    "    length = len(dataset)\n",
    "    print(\"Number of indexable frames:\", length)\n",
    "except Exception as e:\n",
    "    print(\"len(dataset) not available:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be5087f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available keys in sample:\n",
      "  - actions                             | shape=(7,) | dtype=torch.float32\n",
      "  - episode_index                       | shape=() | dtype=torch.int64\n",
      "  - frame_index                         | shape=() | dtype=torch.int64\n",
      "  - image                               | shape=(3, 256, 256) | dtype=torch.float32\n",
      "  - index                               | shape=() | dtype=torch.int64\n",
      "  - state                               | shape=(7,) | dtype=torch.float32\n",
      "  - task                                | shape=<no shape> | dtype=None\n",
      "  - task_index                          | shape=() | dtype=torch.int64\n",
      "  - timestamp                           | shape=() | dtype=torch.float32\n",
      "  - wrist_image                         | shape=(3, 256, 256) | dtype=torch.float32\n",
      "\n",
      "State dim: 7\n",
      "Action dim: 7\n"
     ]
    }
   ],
   "source": [
    "# 4) Peek at one random sample and list keys/shapes\n",
    "\n",
    "idx = 1  # change if you like\n",
    "sample = dataset[idx]\n",
    "print(\"Available keys in sample:\")\n",
    "for k in sorted(sample.keys()):\n",
    "    v = sample[k]\n",
    "    shape = getattr(v, \"shape\", None)\n",
    "    dtype = getattr(v, \"dtype\", None)\n",
    "    print(f\"  - {k:35s} | shape={tuple(shape) if shape is not None else '<no shape>'} | dtype={dtype}\")\n",
    "\n",
    "# Common keys: 'observation.state', 'action', 'timestamp', and possibly multi-camera images\n",
    "state = sample.get('state', None)\n",
    "action = sample.get('actions', None)\n",
    "if state is not None and action is not None:\n",
    "    print(\"\\nState dim:\", int(state.shape[-1]))\n",
    "    print(\"Action dim:\", int(action.shape[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76674219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeRobotDataset({\n",
       "    Repository ID: 'xX-Conan-Xx/pick_up_transparent_bottle',\n",
       "    Number of selected episodes: '45',\n",
       "    Number of selected samples: '5680',\n",
       "    Features: '['image', 'wrist_image', 'state', 'actions', 'timestamp', 'frame_index', 'episode_index', 'index', 'task_index']',\n",
       "})',"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569aaaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Read meta info/stats directly from disk (best-effort)\n",
    "# We'll try several likely locations to find `meta/info.json` and `meta/stats.json`.\n",
    "\n",
    "def guess_dataset_dir(repo_id: str, local_root: str | None) -> Path | None:\n",
    "    candidates = []\n",
    "    if local_root:\n",
    "        candidates.append(Path(local_root))\n",
    "    # Default HF cache location for LeRobot\n",
    "    if repo_id:\n",
    "        candidates.append(Path.home() / \".cache\" / \"huggingface\" / \"lerobot\" / repo_id)\n",
    "        # Some environments use nested folder `~/.cache/huggingface/lerobot/lerobot/<name>`\n",
    "        candidates.append(Path.home() / \".cache\" / \"huggingface\" / \"lerobot\" / \"lerobot\" / repo_id.split('/')[-1])\n",
    "    for p in candidates:\n",
    "        if (p / \"meta\" / \"info.json\").exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "root_dir = guess_dataset_dir(REPO_ID, LOCAL_ROOT if LOCAL_ROOT else None)\n",
    "if root_dir is None:\n",
    "    print(\"Could not locate meta files on disk. If you are streaming, meta may not be local.\")\n",
    "else:\n",
    "    print(\"Dataset directory:\", root_dir)\n",
    "    info_p = root_dir / \"meta\" / \"info.json\"\n",
    "    stats_p = root_dir / \"meta\" / \"stats.json\"\n",
    "    if info_p.exists():\n",
    "        info = json.loads(Path(info_p).read_text())\n",
    "        print(\"\\nmeta/info.json:\\n\", json.dumps(info, indent=2)[:2000], \"...\" if info_p.stat().st_size > 2000 else \"\")\n",
    "    if stats_p.exists():\n",
    "        stats = json.loads(Path(stats_p).read_text())\n",
    "        print(\"\\nmeta/stats.json (truncated):\\n\", json.dumps(stats, indent=2)[:2000], \"...\" if stats_p.stat().st_size > 2000 else \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f8d8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Quick look at actions over the first N frames (contiguous chunk)\n",
    "# This is a coarse check for scale/magnitude and to verify action dimensionality.\n",
    "\n",
    "N = min(MAX_FRAMES, len(dataset) if hasattr(dataset, '__len__') else 128)\n",
    "if N <= 0:\n",
    "    print(\"Dataset appears empty or non-indexable.\")\n",
    "else:\n",
    "    A = []\n",
    "    for i in range(N):\n",
    "        s = dataset[i]\n",
    "        a = s.get('action', None)\n",
    "        if a is None:\n",
    "            break\n",
    "        try:\n",
    "            a_np = a.detach().cpu().numpy()\n",
    "        except Exception:\n",
    "            a_np = np.array(a)\n",
    "        A.append(a_np)\n",
    "    if len(A) > 0:\n",
    "        A = np.stack(A)  # [N, action_dim]\n",
    "        plt.figure()\n",
    "        plt.plot(A)\n",
    "        plt.title(\"Actions over first N frames\")\n",
    "        plt.xlabel(\"t (frame index)\")\n",
    "        plt.ylabel(\"action dims (stacked)\")\n",
    "        plt.show()\n",
    "        print(\"Action array shape:\", A.shape)\n",
    "    else:\n",
    "        print(\"No 'action' key found in samples, or empty dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adbb7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Visualize one image if available (commonly 'observation.images.front_left')\n",
    "import re\n",
    "\n",
    "def find_first_image_key(keys):\n",
    "    # Heuristic: any key that contains 'images' and returns a 3D tensor [C,H,W] or [H,W,C]\n",
    "    for k in keys:\n",
    "        if 'images' in k or 'image' in k:\n",
    "            return k\n",
    "    return None\n",
    "\n",
    "img_key = find_first_image_key(sample.keys())\n",
    "if img_key is None:\n",
    "    print(\"No image-like key detected in the sample.\")\n",
    "else:\n",
    "    img = sample[img_key]\n",
    "    try:\n",
    "        arr = img.detach().cpu().numpy()\n",
    "    except Exception:\n",
    "        arr = np.array(img)\n",
    "\n",
    "    # If channel-first, switch to HWC for matplotlib\n",
    "    if arr.ndim == 3 and arr.shape[0] in (1, 3):\n",
    "        arr = np.transpose(arr, (1, 2, 0))\n",
    "    plt.figure()\n",
    "    if arr.ndim == 2:  # grayscale\n",
    "        plt.imshow(arr, cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(arr)\n",
    "    plt.title(f\"Sample image — key: {img_key}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fe2611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) (Optional) Temporal windows via delta_timestamps (v3 feature)\n",
    "# Recreate dataset with a small temporal stack for one camera if present.\n",
    "\n",
    "try:\n",
    "    from lerobot.datasets.lerobot_dataset import LeRobotDataset as _V3Check  # will fail on v2\n",
    "    # Try to pick a likely image key\n",
    "    key = None\n",
    "    for k in sample.keys():\n",
    "        if 'observation.images' in k:\n",
    "            key = k\n",
    "            break\n",
    "    if key:\n",
    "        delta_timestamps = {key: [-0.2, -0.1, 0.0]}\n",
    "        kwargs = {}\n",
    "        if LOCAL_ROOT:\n",
    "            kwargs['root'] = LOCAL_ROOT\n",
    "        ds_stack = LeRobotDataset(REPO_ID, delta_timestamps=delta_timestamps, **kwargs)\n",
    "        s2 = ds_stack[0]\n",
    "        if key in s2:\n",
    "            print(f\"Temporal stack for {key}:\", s2[key].shape, \"[T, C, H, W]\")\n",
    "    else:\n",
    "        print(\"No obvious image key to demo delta_timestamps.\")\n",
    "except Exception as e:\n",
    "    print(\"delta_timestamps demo skipped (requires v3 API):\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c66847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Helper: quick consistency checks\n",
    "\n",
    "def check_state_action_dims(ds, n_checks: int = 3):\n",
    "    ok = True\n",
    "    for i in range(min(n_checks, len(ds) if hasattr(ds, '__len__') else n_checks)):\n",
    "        s = ds[i]\n",
    "        st = s.get('observation.state', None)\n",
    "        ac = s.get('action', None)\n",
    "        if st is None or ac is None:\n",
    "            print(f\"[idx {i}] missing state/action keys -> state={st is not None}, action={ac is not None}\")\n",
    "            ok = False\n",
    "            continue\n",
    "        sdim = int(st.shape[-1])\n",
    "        adim = int(ac.shape[-1])\n",
    "        print(f\"[idx {i}] state_dim={sdim}, action_dim={adim}\")\n",
    "        if sdim < adim:\n",
    "            print(\"  WARNING: state dim < action dim (unusual unless using compact actions).\")\n",
    "            ok = False\n",
    "    return ok\n",
    "\n",
    "_ = check_state_action_dims(dataset, n_checks=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf57b87",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Notes\n",
    "\n",
    "- If you converted **LIBERO (RLDS)** to LeRobot and see **state dim = 8** but **action dim = 7**, this is expected if your conversion/export only maps the first 7 action channels (e.g., 7-DoF arm without gripper or with a merged gripper command). Always verify the conversion script’s action slicing.  \n",
    "- For more on loading and streaming in v3, see the official docs (\"Load a dataset for training\" and \"Stream a dataset\") — they show the exact keys you’ll get, like `observation.state`, `action`, and camera tensors.  \n",
    "- If your dataset is fully local, set `USE_HUB=False` and **only** `LOCAL_ROOT`. If you still see issues, open `meta/info.json` and check the `repo_id` — pass that in `REPO_ID` as well.\n",
    "\n",
    "Happy debugging! :)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openpi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
